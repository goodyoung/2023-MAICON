{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from skimage.feature import graycomatrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "import torch.optim as optim\n",
    "from ultralytics import YOLO\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\"resnet152\", pretrained=True)\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(2048, 512, 1, 1),\n",
    "                                   nn.BatchNorm2d(512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(512,64,1,1),\n",
    "                                  nn.Dropout(p=0.3),\n",
    "                                  nn.ReLU())\n",
    "        self.fc = nn.Sequential(nn.Linear(64*7*7, 512),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(512, 1))\n",
    "    \n",
    "    def forward(self, x, e_map=None):\n",
    "        x = self.model(x)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.fc(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    model = CustomModel().cuda()\n",
    "    x = torch.zeros((4,3,224,224)).cuda()\n",
    "    y = model(x)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, video_paths: list, labels: list=None, transform=None, mode=\"train\", n=1, randomness=False):\n",
    "        assert mode in ['train', 'test', 'validation','val']\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.n = n\n",
    "        self.randomness = randomness\n",
    "        self.yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "        t = [A.Resize(360,360),\n",
    "             A.CenterCrop(224,224,p=1),\n",
    "             A.Normalize(0.5,0.5),\n",
    "             ToTensorV2()]\n",
    "        if mode == 'train':\n",
    "            t = [A.Resize(360,360),\n",
    "                 A.CenterCrop(224,224,p=1),\n",
    "                 A.HorizontalFlip(p=0.5),\n",
    "                 A.Normalize(0.5,0.5),\n",
    "                 ToTensorV2()]\n",
    "        self.transform = A.Compose(t)\n",
    "        self.crop = A.Compose([A.CenterCrop(180,180,p=1),\n",
    "                               A.Resize(224,224),\n",
    "                               A.Normalize(0.5,0.5),\n",
    "                               ToTensorV2()])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "    \n",
    "    def _get_video_frames(self, cap):\n",
    "        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frames = []\n",
    "        \n",
    "        trial = 0\n",
    "        while len(frames) < self.n:\n",
    "            if self.randomness:\n",
    "                move_to = random.randint(1, num_frames-10*self.n)\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, move_to)\n",
    "            ret, frame = cap.read()\n",
    "            if ret: # 프레임 존재\n",
    "                results = self.yolo([frame])\n",
    "                df = results.pandas().xyxy[0]\n",
    "                df = df[df['name']=='person']\n",
    "                if len(df) >= 1:\n",
    "                    xmin, ymin, xmax, ymax, _,_,_ = df.iloc[0]\n",
    "                    xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
    "                    frame = frame[ymin:ymax,xmin:xmax,:]\n",
    "                    frame = self.transform(image=frame)['image']\n",
    "                    frames.append(frame)\n",
    "                else: # 프레임이 존재하나 욜로 모델이 검출을 못함\n",
    "                    trial += 1\n",
    "                    move_to = random.randint(1, num_frames-10*self.n)\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, move_to)\n",
    "                    if trial == 3:\n",
    "                        trial = 0\n",
    "                        ret, frame = cap.read()\n",
    "                        frame = self.crop(image=frame)['image']\n",
    "                        frames.append(frame)\n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                trial += 1\n",
    "                move_to = random.randint(1, num_frames-10*self.n)\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, move_to)\n",
    "                if trial == 3:\n",
    "                    trial = 0\n",
    "                    ret, frame = cap.read()\n",
    "                    frame = self.crop(image=frame)['image']\n",
    "                    frames.append(frame)\n",
    "                else:\n",
    "                    continue\n",
    "        frames = torch.stack(frames)\n",
    "        frames = frames.detach().clone()\n",
    "        return frames\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        video_path = self.video_paths[index]\n",
    "        # 랜덤 프레임 가져오기\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = self._get_video_frames(cap)\n",
    "        cap.release()\n",
    "        if self.mode == 'test':\n",
    "            return frames\n",
    "        else:\n",
    "            return frames, self.labels[index]\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    train_path = '/mnt/elice/dataset/train'\n",
    "    test_path = '/mnt/elice/dataset/test'\n",
    "    submission_csv = \"./sample_submission_v0.csv\"\n",
    "    save_path = \"./best_resnet152_model.pth\"\n",
    "    \n",
    "    train_fakes = sorted(glob(f\"{train_path}/fake/*\"))\n",
    "    train_reals = sorted(glob(f\"{train_path}/real/*\"))\n",
    "    submit = pd.read_csv(submission_csv)\n",
    "    x_test = [os.path.join(test_path, path) for path in submit[\"path\"].values]\n",
    "    \n",
    "    train_video_paths = train_fakes + train_reals\n",
    "    labels = [1 for _ in range(len(train_fakes))] + [0 for _ in range(len(train_reals))]\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        train_video_paths,\n",
    "        labels,\n",
    "        test_size=0.2,\n",
    "        random_state=777\n",
    "    )\n",
    "\n",
    "\n",
    "    train_dataset = CustomDataset(video_paths=x_train, labels=y_train, mode=\"train\")\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    for idx,(x,y) in enumerate(train_dataloader):\n",
    "        print(x.shape)\n",
    "        if idx==9:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        self.train_path = '/mnt/elice/dataset/train'\n",
    "        self.test_path = '/mnt/elice/dataset/test'\n",
    "        self.submission_csv = \"./sample_submission_v0.csv\"\n",
    "        self.save_path = \"./best_resnet152_model.pth\"\n",
    "        self.EPOCHS = 30\n",
    "        self.LR = 0.001\n",
    "        self.BATCH_SIZE=16\n",
    "        self.MAX_NORM = 5\n",
    "        self.NUM_WORKERS = 0\n",
    "        self.NUM_CLASSES = 1\n",
    "        self.DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.SEED = 1215\n",
    "\n",
    "    def setup(self):\n",
    "        \n",
    "        seed_everything(self.SEED)\n",
    "        # 재현성 위해 sorting\n",
    "        train_fakes = sorted(glob(f\"{self.train_path}/fake/*\"))\n",
    "        train_reals = sorted(glob(f\"{self.train_path}/real/*\"))\n",
    "        self.submit = pd.read_csv(self.submission_csv)\n",
    "        x_test = [os.path.join(self.test_path, path) for path in self.submit[\"path\"].values]\n",
    "        # test_video_paths = sorted(glob(f\"{self.train_path}/*\"))\n",
    "        # fake이면 1 real이면 0으로 할당\n",
    "        train_video_paths = train_fakes + train_reals\n",
    "        labels = [1 for _ in range(len(train_fakes))] + [0 for _ in range(len(train_reals))]\n",
    "        x_train, x_val, y_train, y_val = train_test_split(\n",
    "            train_video_paths,\n",
    "            labels,\n",
    "            test_size=0.2,\n",
    "            random_state=self.SEED\n",
    "        )\n",
    "        \n",
    "        train_dataset = CustomDataset(video_paths=x_train, labels=y_train, mode=\"train\")\n",
    "        val_dataset = CustomDataset(video_paths=x_val, labels=y_val, mode=\"val\")\n",
    "        test_dataset = CustomDataset(video_paths=x_test, labels=None, mode=\"test\")\n",
    "        \n",
    "        self.train_dataloader = DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=self.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=self.NUM_WORKERS,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        self.val_dataloader = DataLoader(\n",
    "            dataset=val_dataset, \n",
    "            batch_size=self.BATCH_SIZE,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        self.test_dataloader = DataLoader(\n",
    "            dataset=test_dataset, \n",
    "            batch_size=1,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        self.model = CustomModel()\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        self.model.to(self.DEVICE)\n",
    "        optimizer = optim.AdamW(params=self.model.parameters(), lr=self.LR, weight_decay=1e-3)\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            cooldown=5,\n",
    "            min_lr=1e-9,\n",
    "            threshold_mode='abs',\n",
    "        )\n",
    "        # AMP : loss scale을 위한 gradscaler\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        best_model = None\n",
    "        \n",
    "        for epoch in range(1, self.EPOCHS+1):\n",
    "            self.model.train()\n",
    "            train_losses = []\n",
    "            for idx,(imgs, labels) in tqdm(enumerate(self.train_dataloader)):\n",
    "                imgs = torch.squeeze(imgs, 1)\n",
    "                imgs = imgs.float().to(self.DEVICE) # (b,3,h,w)\n",
    "                labels = labels.float().to(self.DEVICE)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                # with torch.cuda.amp.autocast():\n",
    "                output = self.model(imgs)\n",
    "                output = output.squeeze(-1)\n",
    "                loss = self.loss_fn(output, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                # scaler.scale(loss).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.MAX_NORM)\n",
    "                optimizer.step()\n",
    "                # scaler.step(optimizer)\n",
    "                # scaler.update()\n",
    "                \n",
    "                train_losses.append(loss.item())\n",
    "                \n",
    "\n",
    "            val_loss, val_acc = self._valid()\n",
    "            train_loss = np.mean(train_losses)\n",
    "            print(f\"EPOCH: {epoch}, TRAIN LOSS: {train_loss:.4f}, VAL LOSS: {val_loss:.4f}, VAL ACC: {val_acc:.4f}\")\n",
    "\n",
    "            if lr_scheduler is not None:\n",
    "                lr_scheduler.step(val_acc)\n",
    "\n",
    "            if best_val_acc <= val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model = deepcopy(self.model)\n",
    "                torch.save(self.model.state_dict(), self.save_path)\n",
    "                early_stop = 0\n",
    "            else:\n",
    "                early_stop += 1\n",
    "\n",
    "            if early_stop > 7:\n",
    "                torch.save(self.model.state_dict(), \"./best_resnet152_model_last.pth\")\n",
    "                break\n",
    "    \n",
    "    def _valid(self):\n",
    "        self.model.eval()\n",
    "        val_losses = []\n",
    "        val_accs = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(self.val_dataloader):\n",
    "                imgs = torch.squeeze(imgs, 1)\n",
    "                imgs = imgs.float().to(self.DEVICE)\n",
    "                labels = labels.float().to(self.DEVICE)\n",
    "                \n",
    "                probs = self.model(imgs)\n",
    "                probs = probs.squeeze(-1)\n",
    "                loss = self.loss_fn(probs, labels)\n",
    "                probs = probs.cpu().detach().numpy()\n",
    "                labels = labels.cpu().detach().numpy()\n",
    "\n",
    "                preds = probs > 0.5\n",
    "                batch_acc = (labels == preds).mean()\n",
    "                val_accs.append(batch_acc)\n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "        return np.mean(val_losses), np.mean(val_accs)\n",
    "    \n",
    "    def test(self, threshold=0.5):\n",
    "        answer_lst = []\n",
    "        logit_lst = []\n",
    "        logit_df = deepcopy(self.submit)\n",
    "        # model load\n",
    "        model = CustomModel(self.NUM_CLASSES).to(self.DEVICE)\n",
    "        model.load_state_dict(torch.load(self.save_path))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for imgs in tqdm(self.test_dataloader):\n",
    "                cur_ans = []\n",
    "                for img in imgs:\n",
    "                    imgs = torch.squeeze(imgs, 1)\n",
    "                    imgs = imgs.float().to(self.DEVICE)\n",
    "\n",
    "                    probs = model(imgs)\n",
    "                    probs = probs.squeeze(-1)\n",
    "                    probs = probs.cpu().detach().numpy()\n",
    "                    logit_lst.append(probs[0])\n",
    "\n",
    "                    preds = 1 if probs > threshold else 0\n",
    "                    cur_ans.append(preds)\n",
    "                cnt_1 = cur_ans.count(1)\n",
    "                cnt_0 = cur_ans.count(0)\n",
    "                ans = 1 if cnt_1 > cnt_0 else 0\n",
    "                answer_lst.append(ans)\n",
    "\n",
    "            self.submit[\"label\"] = answer_lst\n",
    "            self.submit[\"label\"] = self.submit[\"label\"].apply(lambda x: \"fake\" if x else \"real\")\n",
    "            self.submit.to_csv(\"sample_submission3.csv\", index=False)\n",
    "            \n",
    "            logit_df['label'] = logit_lst\n",
    "            logit_df.to_csv(\"sample_submission_logit3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mop1 = pd.read_csv('sample_submission_logit1.csv') # model1\n",
    "mop3 = pd.read_csv('sample_submission_logit2.csv') # model 2\n",
    "mop2 = pd.read_csv('sample_submission_logit3.csv') # model 3\n",
    "mop2.label = (mop2.label + mop3.label*2 + mop1.label*2)/ 5\n",
    "\n",
    "e = mop2.label > 0.25\n",
    "mop2['we'] = e\n",
    "\n",
    "mop2['label'] = np.where(mop2.we==True,'fake','real')\n",
    "#저장\n",
    "mop2.to_csv(\"sample_submission.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
